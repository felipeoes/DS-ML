{"cells":[{"cell_type":"markdown","source":["# Modularização | Python\n\nAutor: Felipe Oliveira\n\n------------\n\n## Objetivo\nEste notebook objetiva a criação de módulos (classes) que auxiliem na automação e otimização do pipeline de modelagem"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab362f39-20a2-41e9-bd12-36acd1637c77"}}},{"cell_type":"markdown","source":["# Pacotes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3b29ceb-5c5a-45db-8861-a8b7ea261a92"}}},{"cell_type":"markdown","source":["## Instalação"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9fc9702f-1b29-4c74-8439-09e979eb6eb8"}}},{"cell_type":"code","source":["dbutils.library.installPyPI(\"shap\")\ndbutils.library.installPyPI(\"lightgbm\")\ndbutils.library.installPyPI(\"xgboost\")\ndbutils.library.installPyPI(\"hyperopt\")\ndbutils.library.installPyPI(\"mlflow\")\n# dbutils.library.restartPython()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"638d4537-a81f-4ac7-97fe-ccf7d6a345a4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[3]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import mlflow\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom hyperopt import hp, rand, tpe, STATUS_OK, Trials, space_eval, fmin, SparkTrials\nfrom hyperopt.pyll.stochastic import sample\n\nfrom sklearn import metrics\nfrom sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, train_test_split, RepeatedStratifiedKFold\n\n#AdaBoost\nfrom sklearn.tree import DecisionTreeClassifier\n\n#LightGBM\nfrom lightgbm import LGBMClassifier\n\n#XgBoost\nfrom xgboost import XGBClassifier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2bd5f74-a2f7-4e31-aaa8-0cf104a92237"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Classes"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e229d08e-3b8e-4a1d-98d7-561f69d4af6c"}}},{"cell_type":"markdown","source":["## Otimizador Bayesiano"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03b5bc83-65ef-4d9b-935e-27691a981867"}}},{"cell_type":"code","source":["classificadores = {\n    \"adaboost\": {\"obj\": AdaBoostClassifier(), \"gradiente\": False, \"base_estimator\": DecisionTreeClassifier(), \"espaco_busca\": {\n        'base_estimator__max_depth': hp.choice(\"base_estimator__max_depth\", [2, 4]),\n        'base_estimator__min_samples_leaf': hp.choice(\"base_estimator__min_samples_leaf\", [25, 100, 300]),\n        'learning_rate': hp.loguniform(\"learning_rate\", np.log(0.01), np.log(0.3)),\n        'algorithm': hp.choice(\"algorithm\", ['SAMME', 'SAMME.R'])\n    }},\n    \"random_forest\": {\"obj\": RandomForestClassifier(), \"n_jobs\": -1, \"gradiente\": False, \"espaco_busca\": {\n        'bootstrap': hp.choice(\"bootstrap\", [True, False]),\n        'max_depth': hp.choice(\"max_depth\", [4, 6, 8]),\n        'min_samples_leaf': hp.choice(\"min_samples_leaf\", [25, 100, 300]),\n        'min_samples_split': hp.choice(\"min_samples_split\", [8, 10, 12]),\n    }},\n    \"light_gbm\": {\"obj\": LGBMClassifier(n_jobs=-1), \"gradiente\": True, \"espaco_busca\": {\n        \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.01), np.log(0.3)),\n        \"num_leaves\": hp.choice(\"num_leaves\", [63, 127]),\n        \"max_depth\": hp.choice(\"max_depth\", [4, 6, 8]),\n        \"feature_fraction\": hp.quniform(\"feature_fraction\", .7, .9, 0.1),\n        \"bagging_fraction\": hp.quniform(\"bagging_fraction\", .7, .9, 0.1),\n        \"min_child_samples\": hp.choice('min_child_samples', [25, 100, 300]),\n        \"lambda_l1\": hp.choice('lambda_l1', [0, .1, 1, 10]),\n        \"lambda_l2\": hp.choice('lambda_l2', [0, .1, 1, 10]),\n    }},\n    \"xgboost\":  {\"obj\": XGBClassifier(n_jobs=-1), \"gradiente\": True, \"espaco_busca\": {\n        \"learning_rate\": hp.loguniform(\"learning_rate\", np.log(0.01), np.log(0.3)),\n        \"max_depth\": hp.choice(\"max_depth\", [4, 6, 8]),\n        \"num_leaves\": hp.choice(\"num_leaves\", [63, 127]),\n        \"colsample_bytree\": hp.quniform(\"colsample_bytree\", .5, .9, 0.1),\n        \"subsample\": hp.quniform(\"subsample\", .5, .9, 0.1),\n        \"min_child_weight\": hp.choice('min_child_weight', [10, 25, 100]),\n    }}\n}\n\nmetricas = {\n    \"auc\": metrics.roc_auc_score,\n}\n\n\nclass OtimizadorBayesiano(object):\n    \"\"\"Classe que automatiza a otimização bayesiana de hiperparâmetros de modelos de machine learning\n\n    Parâmetros\n    ----------\n    classificador : str\n        Nome do classificador a ser utilizado. Suportados: adaboost, random_forest, light_gbm, xgboost\n    n_estimadores : int\n        Número de estimadores a serem utilizados.\n    metrica : str\n        Nome da métrica a ser utilizada.\n    minimizar : bool\n        Se True, otimização será minimizada.\n    espaco_busca : dict\n        Dicionário com os hiperparâmetros a serem otimizados.\n    max_iteracoes : int\n        Número máximo de iterações para otimização.\n    max_avaliacoes : int\n        Número máximo de avaliações para otimização.\n    random_state : int\n        Número da semente para o random_state.\n\n    \"\"\"\n\n    def __init__(self, classificador: str, n_estimadores: int, metrica: str = \"auc\", minimizar: bool = False, espaco_busca: dict = None, max_iteracoes: int = 5, max_avaliacoes: int = 100, random_state: int = 1109):\n        self.__classificador = classificador\n        self.__n_estimadores = n_estimadores\n        self.__espaco_busca = espaco_busca if espaco_busca else classificadores[\n            classificador][\"espaco_busca\"]\n        self.__max_iteracoes = max_iteracoes\n        self.__max_avaliacoes = max_avaliacoes\n        self.__np_random_state = np.random.default_rng(random_state)\n        self.__random_state = random_state\n        self.__metrica = metrica\n        self.__minimizar = minimizar\n        self.__modelo = None\n\n    @property\n    def classificador(self):\n        return self.__classificador\n\n    @classificador.setter\n    def classificador(self, value):\n        self.__classificador = value\n\n    @property\n    def n_estimadores(self):\n        return self.__n_estimadores\n\n    @property\n    def espaco_busca(self):\n        return self.__espaco_busca\n\n    @espaco_busca.setter\n    def espaco_busca(self, value):\n        self.__espaco_busca = value\n\n    @property\n    def max_iteracoes(self):\n        return self.__max_iteracoes\n\n    @property\n    def max_avaliacoes(self):\n        return self.__max_avaliacoes\n\n    @property\n    def random_state(self):\n        return self.__random_state\n    \n    @property\n    def np_random_state(self):\n        return self.__np_random_state\n      \n    @property\n    def metrica(self):\n        return self.__metrica\n\n    @property\n    def minimizar(self):\n        return self.__minimizar\n\n    @property\n    def modelo(self):\n        return self.__modelo\n\n    @modelo.setter\n    def modelo(self, value):\n        self.__modelo = value\n\n    def otimiza_hiperparams(self, X, y, tam_teste=.3, n_divisoes=3, n_repeticoes=2):\n        \"\"\"Função que recebe um conjunto de dados de treino (X), os respectivos rótulos (y) e um tamanho para o conjunto de teste e otimiza os hiperparâmetros de um classificador\"\"\"\n        X_train, X_test, y_train, y_test = train_test_split(\n            X, y, test_size=tam_teste, shuffle=True, random_state=self.random_state)\n        \n        v_cruzada = RepeatedStratifiedKFold(n_splits=n_divisoes, n_repeats=n_repeticoes, random_state=self.random_state)\n        \n        def objective(hiperparams):\n            \"\"\"Função objetivo que recebe um dicionário de hiperparâmetros e retorna o valor da métrica de avaliação (loss) para o classificador avaliado\"\"\"\n            classificador = classificadores[self.classificador]\n\n            params = self.seta_params(classificador)\n\n            modelo = classificador[\"obj\"]\n            modelo.set_params(**params)\n            modelo.set_params(**hiperparams)\n\n            if classificador[\"gradiente\"]:\n                modelo.fit(X=X_train, y=y_train,\n                           eval_set=[(X_test, y_test)],\n                           eval_metric=self.metrica,\n                           early_stopping_rounds=self.max_iteracoes,\n                           verbose=True)\n\n                print(classificador[\"obj\"])\n                score = self.lgbm_score(modelo) if self.classificador == \"light_gbm\" else (modelo.evals_result()[\n                    'validation_0'][self.metrica][modelo.best_iteration] * (1 if self.minimizar else -1))\n            else:\n                modelo.fit(X=X_train, y=y_train)\n                y_pred_proba = modelo.predict_proba(X_train)[:, 1]\n\n                func_score = {metricas[self.metrica]}\n                score = cross_val_score(modelo, X_train, y_train, cv=v_cruzada, scoring=\"roc_auc\", n_jobs=-1).mean()  * (1 if self.minimizar else -1)\n\n            return {'loss': score, 'status': STATUS_OK, 'model': modelo}\n\n        tentativas = SparkTrials(parallelism=32)\n\n        with mlflow.start_run():\n            melhores_params = fmin(fn=objective, space=self.espaco_busca, trials=tentativas,\n                                   algo=tpe.suggest, max_evals=self.max_avaliacoes, verbose=1,\n                                   rstate=self.np_random_state, return_argmin=False)\n\n            classificador = classificadores[self.classificador]\n            modelo_final = classificador[\"obj\"]\n            params = self.seta_params(classificador)\n\n            modelo_final.set_params(**params)\n            modelo_final.set_params(**melhores_params)\n            self.modelo = modelo_final\n\n            self.fit(X_train, y_train, X_test, y_test)\n\n            return melhores_params, tentativas\n\n    def fit(self, X_train, y_train, X_test, y_test):\n        \"\"\"Função que treina um classificador com os dados de treino (X_train, y_train) e avalia o classificador com os dados de teste (X_test, y_test)\"\"\"\n        classificador = classificadores[self.classificador]\n\n        if classificador[\"gradiente\"]:\n            self.modelo.fit(X=X_train, y=y_train, eval_set=[\n                            (X_test, y_test)], eval_metric=self.metrica)\n        else:\n            self.modelo.fit(X=X_train, y=y_train)\n\n        return self.modelo\n\n    def lgbm_score(self, modelo):\n        \"\"\"Função que retorna o valor da métrica de avaliação (loss) para o classificador LGBM\"\"\"\n        return modelo.best_score_[\"valid_0\"][self.metrica] * (1 if self.minimizar else -1)\n\n    def seta_params(self, classificador):\n        \"\"\"Função que seta um dicionário de hiperparâmetros para o classificador a ser treinado\"\"\"\n        params = {\n            \"n_estimators\": self.n_estimadores,\n        }\n\n        extra_params = {\n            \"n_jobs\": classificador.get(\"n_jobs\"),\n            \"base_estimator\": classificador.get(\"base_estimator\")\n        }\n\n        for key, value in extra_params.items():\n            if value:\n                params.update({key: value})\n\n        return params"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77c907cb-208e-46ea-a4fb-144d002e5fde"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Visualizador"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26341f75-28f7-40aa-b687-4270a3125e19"}}},{"cell_type":"code","source":["class Visualizador(object):\n    \"\"\"Classe auxiliar para a visualização de dados durante a modelagem\n\n    Parâmetros:\n    base: DataFrame do pandas\n        Base de dados a ser visualizada\n    base_cat: DataFrame do pandas\n        Base de dados categorizada a ser visualizada (opcional e específica para alguns casos de uso)\n     \"\"\"\n\n    def __init__(self, base: pd.DataFrame, base_cat: pd.DataFrame = None):\n        self.__base = base\n        self.__base_cat = base_cat\n        self.__tab_KS_pivot = None\n        self.__tab_decis = None\n        self.__prefixos = set()\n        \n\n    @property\n    def base(self):\n      return self.__base\n\n    @property\n    def base_cat(self):\n      return self.__base_cat\n\n    @property\n    def tab_KS_pivot(self):\n      return self.__tab_KS_pivot\n\n    @tab_KS_pivot.setter\n    def tab_KS_pivot(self, value):\n      self.__tab_KS_pivot = value\n      \n    @property\n    def tab_decis(self):\n      return self.__tab_decis\n\n    @tab_KS_pivot.setter\n    def tab_decis(self, value):\n      self.__tab_decis = value\n\n    @property\n    def prefixos(self):\n       return self.__prefixos\n\n    def __adiciona_prefixo__(self, prefixos: str or list):\n        \"\"\" Função que adiciona prefixos ao conjunto de prefixos\"\"\"\n        self.__prefixos.add(prefixos) if type(\n            prefixos) == str else self.__prefixos.update(prefixos)\n    \n    \n    def __cria_quantis__(self, base: pd.DataFrame, modelo: str, n_quantis: int, nome_var: str, col_safra: str = None, safras: list = []):\n        \"\"\"Função que cria 'n_quantis' numa base a partir de um determinado modelo e uma variável target (nome_var) \"\"\"\n        base = cria_fxs(base, base, modelo, n_quantis, nome_var)\n        base = base[base[col_safra].isin(safras)] if col_safra and len(safras) > 0 else base\n        \n        globals()[f\"tabfxs{modelo}\"] = pd.crosstab(base[nome_var],columns=modelo,values=base[target],aggfunc=np.mean)\n        \n        return globals()[f\"tabfxs{modelo}\"]\n      \n    def tabela_qs(self, modelos: list or str, safras: list = [], col_safra: str = \"\", target: str =\"inad30\"):\n      \"\"\" Função que recebe uma lista com safras específicas, o nome da coluna que representa as safras no df e retorna uma tabela com os modelos e suas respectivas ordenações de inad30 por decil\"\"\"\n      tabs = []\n      \n      self.__adiciona_prefixo__(modelos)\n      base_temp = self.base.copy()\n      \n      if isinstance(modelos, str):\n        col_qs = self.__cria_quantis__(base_temp, modelos, 10, f\"qs_{modelos}\")\n        \n        return col_qs * 100\n      \n      for modelo in modelos:\n        nome_var_qs =  f\"qs_{modelo}\"\n        \n        col_qs = self.__cria_quantis__(base_temp, modelo, 10, nome_var_qs)\n        tabs.append(col_qs)\n\n      tab_qs = tabs[0].join(tabs[1:], rsuffix='r') * 100 \n      self.__tab_decis = tab_qs\n      \n      return tab_qs\n    \n    def __popula_conjunto__(self, opcoes: list):\n      conj_modelos = {}\n      \n      for opcao in opcoes:\n        if opcao == \"aberto\":\n          conj_modelos[opcao] = [modelo for modelo in modelos if opcao in modelo and \"continuo\" not in modelo]\n        else :\n          conj_modelos[opcao] = [modelo for modelo in modelos if opcao in modelo]\n      return conj_modelos\n          \n      \n    def ks_por_safra(self, modelos: list, safras: list, agrupar: bool = False, kind=\"line\", title=\"KS do modelo por safra\", ylabel=\"KS\", figsize=(8,6), grid: bool = False, tab_KS_pivot=None):\n      \"\"\" Função que recebe uma lista com safras específicas e retorna uma lista com três gráficos (restrito, aberto , aberto_continuo) com o KS de cada modelo por safra\"\"\"\n      safras.sort()\n      xlim_min = safras[0]\n      \n      if not agrupar:\n        grafico = self.tab_KS_pivot[modelos].plot(kind=kind, title=f\"{title}\", figsize=figsize, marker='.', markersize=16)\n        \n        plt.ylabel(\"KS\")\n        plt.legend([*conjunto, col_target])\n        plt.xlabel('Safra')\n        plt.grid(grid)\n        return grafico\n      \n      opcoes = [\"restrito\", \"aberto\", \"aberto_continuo\"]\n\n      conj_modelos = self.__popula_conjunto__(opcoes)\n      \n      for conjunto in conj_modelos:\n        if tab_KS_pivot:\n          globals()[f\"ax_{opcao}\"] = tab_KS_pivot[conjunto].plot(kind=kind, title=f\"{title} ({opcao.capitalize()})\", figsize=figsize, marker='.', markersize=16)\n        else:\n          globals()[f\"ax_{opcao}\"] = self.tab_KS_pivot[conjunto].plot(kind=kind, title=f\"{title} ({opcao.capitalize()})\", figsize=figsize, marker='.', markersize=14)\n        plt.ylabel(\"KS\")\n        plt.legend(conjunto)\n        \n    \n    def tabela_ks_por_safra(self, target, modelos: list, safras: list):\n        \"\"\" Função que recebe uma lista com nomes de modelos, coluna target e safras específicas e retorna uma tabela pivot com os modelos e seus respectivos KS's por safra\"\"\"\n        lsafra=[]\n        lscore=[]\n        lKS=[]\n        lN=[]\n        ltx=[]\n\n        for modelo in [*modelos]:\n            for safra in safras:\n                temp_calc=calc_perf(self.base[self.base.Safra_main==safra], modelo, target)\n                lsafra=lsafra+[safra]\n                lscore=lscore+[modelo]\n                lKS=lKS+[np.round(temp_calc[0],4)]\n                lN=lN+temp_calc[1]\n                ltx=ltx+temp_calc[2]\n\n        tab_KS = pd.DataFrame(\n            {\n            'modelo':lscore,\n            'Safra':lsafra,    \n            'KS':lKS\n            }\n        )\n        tab_KS = tab_KS.drop_duplicates()\n\n        tab_KS_pivot=tab_KS.pivot(index='Safra',columns='modelo',values='KS')\n        self.__tab_KS_pivot = tab_KS_pivot\n\n        return tab_KS_pivot\n    \n    \n    def __cria_grafico__(self, opcao, modelos: list, kind, title, figsize, tab_decis: pd.DataFrame = None):\n      subtitulo = \"\" \n      if isinstance(opcao, str):\n        subtitulo = opcao.capitalize()\n        \n      if tab_decis is not None:\n          globals()[f\"ax_{opcao}\"] = self.tab_decis[modelos].plot(kind=kind, title=f\"{title} ({subtitulo})\", figsize=figsize, marker='.', markersize=14)\n      else:\n          globals()[f\"ax_{opcao}\"] = tab_decis[modelos].plot(kind=kind, title=f\"{title} ({subtitulo})\", figsize=figsize, marker='.', markersize=16)\n          \n          \n    def ordenacao_inad_decil(self, modelos: list, tab_decis: pd.DataFrame = None, agrupar: bool = False, kind=\"line\", title=\"Ordenação inad por decil\", figsize=(8,6), grid: bool = False):\n      \n      conj_modelos = {}\n  \n      if agrupar:\n          opcoes = [\"restrito\", \"aberto\", \"aberto_continuo\"]\n          conj_modelos = self.__popula_conjunto__(opcoes)\n      else:\n          self.__cria_grafico__(0, modelos, tab_decis=tab_decis, kind=kind,title=title, figsize=figsize)\n        \n        \n      for indice, conjunto in enumerate(conj_modelos):\n        if tab_decis is not None:\n          globals()[f\"ax_{indice}\"] = self.tab_decis[conjunto].plot(kind=kind, title=f\"{title} ({opcao.capitalize()})\", figsize=figsize, marker='.', markersize=14)\n        else:\n          globals()[f\"ax_{indice}\"] = tab_decis[conjunto].plot(kind=kind, title=f\"{title} ({opcao.capitalize()})\", figsize=figsize, marker='.', markersize=16)\n          \n      plt.ylabel(\"%inad30\")\n      plt.legend(title=\"modelo\")\n      plt.xlabel('Decil')\n      plt.grid(grid)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3221ae5-0b0e-450d-b34b-3a426965d72f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Modulos","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3786671719466035}},"nbformat":4,"nbformat_minor":0}
